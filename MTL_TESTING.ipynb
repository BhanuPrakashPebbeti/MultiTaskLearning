{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "mhz_OqL5Sa2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f59ed3-040d-4e40-a51b-8a771e276e35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bQpe4Q_3opaY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import cv2\n",
        "import timm\n",
        "import torch as T\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, SequentialSampler\n",
        "from torchvision import transforms\n",
        "from copy import deepcopy\n",
        "\n",
        "device = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, backbone = 'resnet18', device = 'cuda'):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.backbone = timm.create_model(backbone, pretrained = True)\n",
        "        self.List = list(self.backbone.children())[:-2]\n",
        "        self.device = device\n",
        "    def forward(self,X):\n",
        "        outputs = []\n",
        "        X = X.float()\n",
        "        for i,layer in enumerate(self.List):\n",
        "            X = layer(X)\n",
        "            if i>1:\n",
        "                outputs.append(X)\n",
        "        return outputs\n",
        " \n",
        "class objdet_Decoder(nn.Module):\n",
        "    '''series of convs ==> final output heatmap'''\n",
        "    def __init__(self, n_classes, stride = 2, device = 'cuda'):\n",
        "        super(objdet_Decoder, self).__init__()\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode = 'bilinear')\n",
        "        self.conv1 = nn.Conv2d(512,256,(3,3),padding = 1)  # 16\n",
        "        self.conv2 = nn.Conv2d(256,128,(3,3),padding = 1)  #32\n",
        "        self.conv3 = nn.Conv2d(128,64,(3,3),padding = 1) #64\n",
        "        self.conv4 = nn.Conv2d(64,32,(3,3),padding = 1) #128\n",
        "        self.hmap = nn.Conv2d(32,n_classes,(1,1)) #128\n",
        "        self.regs = nn.Conv2d(32,2,(1,1))\n",
        "        self.w_h_ = nn.Conv2d(32,2,(1,1))\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,X):\n",
        "        X = self.upsample(X[-1])\n",
        "        X = F.relu(self.conv1(X))\n",
        "        X = self.upsample(X)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = self.upsample(X)\n",
        "        X = F.relu(self.conv3(X))\n",
        "        X = self.upsample(X)\n",
        "        X = F.relu(self.conv4(X))\n",
        "        return [[T.sigmoid(self.hmap(X)), T.sigmoid(self.regs(X)), T.sigmoid(self.w_h_(X))]]\n",
        "        \n",
        "        \n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        " \n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super(DoubleConv,self).__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        " \n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "        \n",
        "class up(nn.Module):\n",
        "    '''down samling--->double conv'''\n",
        "    def __init__(self,in_channels, out_channels,last_layer=False):\n",
        "        super(up,self).__init__()\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode = 'bilinear')\n",
        "        if last_layer:\n",
        "            self.conv = DoubleConv(in_channels*2,out_channels)\n",
        "        else:\n",
        "            self.conv = DoubleConv(in_channels*3//2,out_channels)   #since we are concatenating \n",
        "    def forward(self,x1,x2):\n",
        "        x1 = self.upsample(x1)\n",
        "        X = T.cat([x1,x2],dim=1)\n",
        "        X = self.conv(X)\n",
        "        return X\n",
        "        \n",
        "class seg_decoder(nn.Module):\n",
        "    def __init__(self, n_classes = 23, device=\"cuda\"):\n",
        "        super(seg_decoder, self).__init__()\n",
        "        \n",
        "        self.up1 = up(512,256)\n",
        "        self.up2 = up(256,128)\n",
        "        self.up3 = up(128,64)\n",
        "        self.up4 = up(64,32,last_layer=True)\n",
        "        self.out_conv = nn.Conv2d(32,n_classes,(3,3),padding=1)\n",
        "        self.device = device\n",
        "    \n",
        "    def forward(self,outputs):\n",
        "        X = self.up1(outputs[-1],outputs[-2])\n",
        "        X = self.up2(X,outputs[-3])\n",
        "        X = self.up3(X,outputs[-4])\n",
        "        X = self.up4(X,outputs[-6])\n",
        "        X = self.out_conv(X)\n",
        "        return X\n",
        "     \n",
        "class MTL_Model(nn.Module):\n",
        "    def __init__(self,n_classes = 35,device='cuda'):\n",
        "        super(MTL_Model,self).__init__()\n",
        "        self.encoder = Encoder(device=device)\n",
        "        self.seg_decoder = seg_decoder(n_classes ,device=device)\n",
        "        self.dep_decoder = seg_decoder(n_classes = 1,device=device)\n",
        "        self.obj_decoder = objdet_Decoder(n_classes = 15,device=device)\n",
        "        self.to(device)\n",
        "        \n",
        "    def forward(self,X):\n",
        "        outputs = self.encoder(X)\n",
        "        seg_maps = self.seg_decoder(outputs)\n",
        "        depth_maps = self.dep_decoder(outputs)\n",
        "        detection_maps = self.obj_decoder(outputs)\n",
        "        return (seg_maps, T.sigmoid(depth_maps),detection_maps)\n",
        "\n",
        "PALETTE = {\n",
        "    (128, 64,128)  : 0 , #'road' \n",
        "    (250,170,160) : 1 , #'parking'  \n",
        "    ( 81,  0, 81) : 2 ,#drivable fallback\n",
        "    (244, 35,232) : 3 , #sidewalk\n",
        "    (230,150,140) : 4 , #rail track\n",
        "    (152,251,152) : 5 ,#non-drivable fallback\n",
        "    (220, 20, 60) : 6 ,#person\n",
        "    (246, 198, 145) : 7 ,#animal\n",
        "    (255,  0,  0) : 8 , #rider\n",
        "    (  0,  0,230) : 9 ,#motorcycle\n",
        "    (119, 11, 32) : 10 ,  #bicycle\n",
        "    (255, 204, 54) : 11,#autorickshaw\n",
        "    (  0,  0,142) : 12,  #car\n",
        "    (  0,  0, 70) : 13, #truck\n",
        "    (  0, 60,100) : 14,    #bus\n",
        "    (  0,  0, 90) : 15,#caravan\n",
        "    (  0,  0,110) : 16,#trailer\n",
        "    (  0, 80,100) : 17,#train\n",
        "    (136, 143, 153) : 18,#vehicle fallback\n",
        "    (220, 190, 40) : 19,#curb\n",
        "    (102,102,156) : 20,#wall\n",
        "    (190,153,153) : 21,#fence\n",
        "    (180,165,180) : 22,#guard rail\n",
        "    (174, 64, 67) : 23,#billboard\n",
        "    (220,220,  0) : 24,#traffic sign\n",
        "    (250,170, 30) : 25,#traffic light\n",
        "    (153,153,153) : 26,#pole\n",
        "    (169, 187, 214) : 27,#obs-str-bar-fallback\n",
        "    ( 70, 70, 70) : 28,#building\n",
        "    (150,100,100) : 29,#bridge\n",
        "    (150,120, 90) : 30,#tunnel\n",
        "    (107,142, 35) : 31,#vegetation\n",
        "    ( 70,130,180) : 32,#sky\n",
        "    (169, 187, 214) : 33,#fallback background\n",
        "    (  0,  0,  0) : 34#unlabeled\n",
        "}\n",
        "\n",
        "def convert_from_color_segmentation(arr_3d):\n",
        "    arr_3d = np.array(arr_3d)\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "    palette = PALETTE\n",
        "    for i in range(0, arr_3d.shape[0]):\n",
        "        for j in range(0, arr_3d.shape[1]):\n",
        "            key = (arr_3d[i, j, 2], arr_3d[i, j, 1], arr_3d[i, j, 0])\n",
        "            arr_2d[i, j] = palette.get(key,34) # default value if key was not found is 0\n",
        "\n",
        "    return arr_2d\n",
        "\n",
        "def labels_to_cityscapes_palette(array):\n",
        "    result = np.zeros((array.shape[0], array.shape[1], 3))\n",
        "    for value, key in PALETTE.items():\n",
        "        result[np.where(array == key)] = (value[2],value[1],value[0])\n",
        "    return result/255\n",
        "\n",
        "def to_one_hot(mask, n_classes=35):\n",
        "    one_hot = np.zeros((mask.shape[0], mask.shape[1], n_classes))\n",
        "    for i, unique_value in enumerate(np.unique(mask)):\n",
        "        one_hot[:, :, unique_value][mask == unique_value] = 1\n",
        "    return one_hot\n",
        "\n",
        "input_size_x,input_size_y = (640, 480)\n",
        "MODEL_SCALE = 2\n",
        "\n",
        "def _gather_feature(feat, ind, mask=None):\n",
        "    dim = feat.size(2)\n",
        "    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
        "    feat = feat.gather(1, ind)\n",
        "    if mask is not None:\n",
        "        mask = mask.unsqueeze(2).expand_as(feat)\n",
        "        feat = feat[mask]\n",
        "        feat = feat.view(-1, dim)\n",
        "    return feat\n",
        "\n",
        "def _tranpose_and_gather_feature(feat, ind):\n",
        "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
        "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
        "    feat = _gather_feature(feat, ind)\n",
        "    return feat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MTL_Model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqvkbU2gbaFT",
        "outputId": "70bb4a29-3e74-4ace-a240-4483af83a8e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a45ffCf0opao",
        "outputId": "5759da5b-9735-45c0-cb2a-63071ea38e2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTL_Model(\n",
              "  (encoder): Encoder(\n",
              "    (backbone): ResNet(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "      (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (seg_decoder): seg_decoder(\n",
              "    (up1): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up2): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up3): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up4): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (out_conv): Conv2d(32, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (dep_decoder): seg_decoder(\n",
              "    (up1): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up2): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up3): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (up4): up(\n",
              "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "      (conv): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (out_conv): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (obj_decoder): objdet_Decoder(\n",
              "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (hmap): Conv2d(32, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (regs): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (w_h_): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# model.load_state_dict(T.load(\"/content/model_v3-1.8697537092062144.pth\",map_location=device))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cc3KveKmopao"
      },
      "outputs": [],
      "source": [
        "def showbox(img, hm, off,regr,box_=None):\n",
        "    sample = cv2.resize(img,(640, 480))\n",
        "    boxes = ctdet_decode(hm,off,regr)\n",
        "    \n",
        "    classes = {0:\"bicycle\",1:\"bus\",2:\"traffic sign\",3:\"train\",4:\"motorcycle\",5:\"car\",6:\"traffic light\",7:\"person\",8:\"vehicle fallback\",9:\"truck\",10:\"autorickshaw\",11:\"animal\",12:\"caravan\",13:\"rider\",14:\"trailer\"}\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    fontScale = 0.5\n",
        "    thickness = 1\n",
        "    color =(250, 0, 0)\n",
        "    for box in boxes:\n",
        "        cv2.rectangle(sample,\n",
        "                      (int(box[0]-(box[2]/2)), int(box[1]-(box[3]/2))),\n",
        "                      (int(box[0]+(box[2]/2)), int(box[1]+(box[3]/2))),\n",
        "                      color, 2)\n",
        "    return sample\n",
        "\n",
        "def _nms(heat, kernel=7):\n",
        "    hmax = F.max_pool2d(heat, kernel, stride=1, padding=(kernel - 1) // 2)\n",
        "    keep = (hmax == heat).float()\n",
        "    return heat * keep\n",
        "\n",
        "\n",
        "def _topk(scores, K=40, threshold=0.2):\n",
        "    batch, cat, height, width = scores.size()\n",
        "\n",
        "    topk_scores, topk_inds = T.topk(scores.view(batch, cat, -1), K)\n",
        "\n",
        "    topk_inds = topk_inds % (height * width)\n",
        "    topk_ys = (topk_inds / width).int().float()\n",
        "    topk_xs = (topk_inds % width).int().float()\n",
        "\n",
        "    topk_score, topk_ind = T.topk(topk_scores.view(batch, -1), K)\n",
        "    topk_clses = (topk_ind / K).int()\n",
        "    topk_inds = _gather_feature(topk_inds.view(batch, -1, 1), topk_ind).view(batch, K)\n",
        "    topk_ys = _gather_feature(topk_ys.view(batch, -1, 1), topk_ind).view(batch, K)\n",
        "    topk_xs = _gather_feature(topk_xs.view(batch, -1, 1), topk_ind).view(batch, K)\n",
        "    mask = T.where(topk_score>threshold, True, False)\n",
        "    return topk_score[:,mask[0]], topk_inds[:,mask[0]], topk_clses[:,mask[0]], topk_ys[:,mask[0]], topk_xs[:,mask[0]], len(topk_score[:,mask[0]][0])\n",
        "\n",
        "\n",
        "def ctdet_decode(hmap, regs, w_h_, K=40):\n",
        "    batch, cat, height, width = hmap.shape\n",
        "    batch = 1\n",
        "    input_size_x = 640\n",
        "    input_size_y = 480\n",
        "    hmap = _nms(hmap)  # perform nms on heatmaps\n",
        "\n",
        "    scores, inds, clses, ys, xs, M = _topk(hmap, K=K)\n",
        "    regs = _tranpose_and_gather_feature(regs, inds)\n",
        "    regs = regs.view(batch, M, 2)\n",
        "    xs = xs.view(batch, M, 1)*MODEL_SCALE + regs[:, :, 0:1]\n",
        "    ys = ys.view(batch, M, 1)*MODEL_SCALE + regs[:, :, 1:2]\n",
        "    w_h_ = _tranpose_and_gather_feature(w_h_, inds)\n",
        "    w_h_ = w_h_.view(batch, M, 2)\n",
        "\n",
        "    clses = clses.view(batch, M, 1).float()\n",
        "    scores = scores.view(batch, M, 1)\n",
        "    bboxes = T.cat([xs ,ys  ,w_h_[..., 0:1]*input_size_x ,w_h_[..., 1:2]*input_size_y ], dim=2)\n",
        "    detections = T.cat([bboxes, scores, clses], dim=2)\n",
        "    return detections.cpu().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXoSg_Z5opap"
      },
      "outputs": [],
      "source": [
        "class MTL_TEST_DETECTOR(Dataset):\n",
        "    def __init__(self, filename=None, input_size=(640, 480), output_size=(320, 240)):\n",
        "        super().__init__()\n",
        "        self.filename = filename\n",
        "        self.dataset = pd.read_csv(self.filename)\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.input_size_x = self.input_size[0]\n",
        "        self.input_size_y = self.input_size[1]\n",
        "        self.MODEL_SCALE = self.input_size[0]//self.output_size[0]\n",
        "        self.preprocess = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        self.resize1 = transforms.Compose([transforms.Resize(self.input_size)])\n",
        "        self.resize2 = transforms.Compose([transforms.Resize(self.output_size)])\n",
        "\n",
        "\n",
        "    def __len__(self): return len(self.dataset)\n",
        "    \n",
        "    def __getitem_internal__(self, idx, preprocess=True):\n",
        "        target = self.dataset.iloc[idx]\n",
        "        rgb_image = cv2.imread(target[\"Path\"])\n",
        "        height, width, channels = rgb_image.shape\n",
        "        rgb_image = cv2.resize(rgb_image,self.input_size)\n",
        "        boxes = literal_eval(target[\"bbox\"])\n",
        "        b = []\n",
        "        for i,a in enumerate(boxes):\n",
        "            box_ = a[\"bbox\"]\n",
        "            box = convert(box_,width,height)\n",
        "            b.append(box)\n",
        "        if preprocess:\n",
        "            rgb_image = self.preprocess(np.array(rgb_image))\n",
        "        else:\n",
        "            rgb_image = transforms.ToTensor()(np.array(rgb_image))\n",
        "        return (rgb_image, b)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.__getitem_internal__(idx, True)\n",
        "    \n",
        "    def raw(self, idx):\n",
        "        return self.__getitem_internal__(idx, False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "6jCl87R7Rv6Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODWMEzoeopap"
      },
      "outputs": [],
      "source": [
        "# test_dataloader = MTL_TEST_DETECTOR(\"/home/b170007ec/Programs/MTL/DSD_MTL/Dataset/val_dataset.csv\")\n",
        "# device = T.device(\"cpu\")\n",
        "# j=10\n",
        "# for i in range(j,j+30,5):\n",
        "#     matrix = []\n",
        "#     for a in range(5):\n",
        "#         rgb ,box = test_dataloader[i+a]\n",
        "#         rgb_raw,_ = test_dataloader.raw(i+a)\n",
        "#         rgb_raw = rgb_raw.permute(1,2,0)\n",
        "#         rgb = T.unsqueeze(rgb, 0)\n",
        "#         rgb = rgb.to(device)\n",
        "#         y_pred = model(rgb)\n",
        "#         y_pred_ = F.softmax(y_pred[0],dim=1)\n",
        "#         pseg = T.squeeze(y_pred_,0)\n",
        "#         pseg = T.argmax(pseg, dim=0)\n",
        "#         pdepth = T.squeeze(y_pred[1],0)\n",
        "#         pdepth = pdepth.permute(1,2,0)\n",
        "#         pdepth = pdepth.reshape(240,320)\n",
        "#         hmap, regs, w_h_ = zip(*y_pred[2])\n",
        "#         d = showbox(rgb_raw.numpy(), hmap[0].detach(), regs[0].detach(),w_h_[0].detach())\n",
        "#         matrix.append([rgb_raw.numpy(),labels_to_cityscapes_palette(pseg.cpu().detach().numpy()),pdepth.cpu().detach().numpy(),d])\n",
        "    \n",
        "#     fig, ax = plt.subplots(5, 4,figsize=(40,40))\n",
        "#     for k in range(5):\n",
        "#         for j in range(4):\n",
        "#             ax[k][j].imshow(matrix[k][j])\n",
        "#             ax[k][j].set_xticks([])\n",
        "#             ax[k][j].set_yticks([])\n",
        "#     plt.savefig(\"END_TO_END_MTL_{}\".format(i))\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siE08XDXopas"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# fps = 30\n",
        "# preprocess = transforms.Compose([\n",
        "#                 transforms.ToTensor(),\n",
        "#                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#         ])\n",
        "# video_capture = cv2.VideoCapture(\"/home/b170007ec/Programs/MTL/DSD_MTL/video.mp4\")\n",
        "# size=(1280,960)\n",
        "# frames = 0\n",
        "# model.eval()\n",
        "# while(video_capture.isOpened()):\n",
        "#     ret, frame = video_capture.read()\n",
        "#     if frames == 110:\n",
        "#         rgb_raw = cv2.resize(frame,(640, 480))\n",
        "#         rgb = preprocess(rgb_raw)\n",
        "#         rgb = T.unsqueeze(rgb, 0)\n",
        "#         rgb = rgb.to(device)\n",
        "#         y_pred = model(rgb)\n",
        "#         y_pred_ = F.softmax(y_pred[0],dim=1)\n",
        "#         pseg = T.squeeze(y_pred_,0)\n",
        "#         pseg = T.argmax(pseg, dim=0)\n",
        "#         pseg = labels_to_cityscapes_palette(pseg.cpu().detach().numpy())\n",
        "#         pdepth = T.squeeze(y_pred[1],0)\n",
        "#         pdepth = pdepth.permute(1,2,0)\n",
        "#         pdepth = pdepth.reshape(240,320)\n",
        "\n",
        "#         hmap, regs, w_h_ = zip(*y_pred[2])\n",
        "#         d = showbox(rgb_raw, hmap[0].detach(), regs[0].detach(),w_h_[0].detach())\n",
        "#         fig = plt.figure(figsize =(8, 8))\n",
        "#         plt.imshow(rgb_raw)\n",
        "#         plt.tick_params(left = False, right = False , labelleft = False ,\n",
        "#                 labelbottom = False, bottom = False)\n",
        "#         plt.savefig(\"rgb.png\")\n",
        "#         plt.show()\n",
        "#         fig = plt.figure(figsize =(8, 8))\n",
        "#         plt.imshow(pseg)\n",
        "#         plt.tick_params(left = False, right = False , labelleft = False ,\n",
        "#                 labelbottom = False, bottom = False)\n",
        "#         plt.savefig(\"seg.png\")\n",
        "#         plt.show()\n",
        "#         fig = plt.figure(figsize =(8, 8))\n",
        "#         plt.imshow(pdepth.cpu().detach().numpy(),cmap='magma')\n",
        "#         plt.tick_params(left = False, right = False , labelleft = False ,\n",
        "#                 labelbottom = False, bottom = False)\n",
        "#         plt.savefig(\"dep.png\")\n",
        "#         plt.show()\n",
        "#         fig = plt.figure(figsize =(8, 8))\n",
        "#         plt.imshow(d)\n",
        "#         plt.tick_params(left = False, right = False , labelleft = False ,\n",
        "#                 labelbottom = False, bottom = False)\n",
        "#         plt.savefig(\"det.png\")\n",
        "#         plt.show()\n",
        "#         break\n",
        "#     frames += 1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "MTL_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}